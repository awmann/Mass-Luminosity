{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emcee\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import corner\n",
    "import scipy.optimize as op\n",
    "\n",
    "%matplotlib inline  \n",
    "\n",
    "# some important variables\n",
    "g = 6.6743e-8\n",
    "msun = 1.989e33\n",
    "au = 1.496e13\n",
    "pi = 3.14159"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbin = 58 ## number of binaries in sample\n",
    "nvar = 5\n",
    "\n",
    "## read in delK, parallax\n",
    "delk = np.zeros(nbin)\n",
    "edelk = np.zeros(nbin)\n",
    "plxval = np.zeros(nbin)\n",
    "plxprior = np.zeros(nbin)\n",
    "name = strs = ['']*nbin\n",
    "k = np.zeros(nbin)\n",
    "ek = np.zeros(nbin)\n",
    "feh = np.zeros(nbin)\n",
    "f = open('data2.txt','r')\n",
    "header1 = f.readline()\n",
    "i=0\n",
    "for line in f:\n",
    "    line = line.strip()\n",
    "    columns = line.split()\n",
    "    name[i] = columns[0]\n",
    "    delk[i] = float(columns[1])\n",
    "    edelk[i] = float(columns[2])\n",
    "    plxval[i] = float(columns[3])\n",
    "    plxprior[i] = float(columns[4])\n",
    "    k[i] = float(columns[5])\n",
    "    ek[i] = float(columns[6])\n",
    "    feh[i] = float(columns[8])\n",
    "    i+=1\n",
    "f.close()\n",
    "\n",
    "## now for the sma**3/per**2\n",
    "f = open('fits.txt','r')\n",
    "header1 = f.readline()\n",
    "i=0\n",
    "smaper = np.zeros(nbin)\n",
    "esmaper = np.zeros(nbin)\n",
    "for line in f:\n",
    "    line = line.strip()\n",
    "    columns = line.split()\n",
    "    smaper[i] = float(columns[0])\n",
    "    esmaper[i] = float(columns[1])\n",
    "    i+=1\n",
    "f.close()\n",
    "\n",
    "fluxratio = 10.0**(delk/2.5)\n",
    "del_eps = 2.5*np.log10(1.0+1.0/fluxratio)\n",
    "kp = del_eps+k\n",
    "ks = kp + delk\n",
    "\n",
    "# compute MC errors on Kp, Ks\n",
    "mcsize = 50000\n",
    "ekp = kp*0.\n",
    "eks = ks*0.\n",
    "for i in range(0,len(ks)):\n",
    "    ktmp = k[i]+ek[i]*np.random.standard_normal(mcsize)\n",
    "    deltmp = delk[i]+edelk[i]*np.random.standard_normal(mcsize)\n",
    "    fluxratio = 10.0**(deltmp/2.5)\n",
    "    del_eps = 2.5*np.log10(1.0+1.0/fluxratio)\n",
    "    kpt = del_eps+ktmp\n",
    "    kst = kp[i] + ktmp\n",
    "    ekp[i] = np.std(kpt)\n",
    "    eks[i] = np.std(kst)\n",
    "\n",
    "\n",
    "result_ben = np.array([0.2311,-0.1352, 0.0400, 0.0038, -0.0032]) # benedict fit value\n",
    "result1 = np.array([0.23323026,-0.10887911, 0.019990399, 0.00027286744, -0.00046073982])# Mann fit value\n",
    "result2 = plxval\n",
    "result_delf = [0.001*1.8,0.001*6.12,0.001*13.205,-6.2315*0.001,0.001*0.37529]\n",
    "result3= np.array([-0.663541,-0.212175 , 0.00594868 ,  0.00641549, -0.000416446]) ## one I measured in IDL\n",
    "result3= np.array([-0.64329003970411125,-0.20043764801036046,-0.0041776516821012992,0.0033655838569557478,0.00030012649616073089])\n",
    "fehcoeff = np.array([0.01])\n",
    "result = np.concatenate([result3[0:4],fehcoeff,result2])\n",
    "#print result3[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = (au**3.)*((4.0*np.pi**2.)/(g*msun))\n",
    "empmass = factor*smaper/plxval**3\n",
    "e_empmass = empmass*np.sqrt((esmaper/smaper)**2 +9.0*(plxprior/plxval)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnlike(theta, smaper, esmaper, kp, ks, ekp, eks, feh, nvar):\n",
    "    zp = 7.5e0\n",
    "    au = 1.496e13\n",
    "    msun = 1.989e33\n",
    "    g = 6.6743e-8 \n",
    "    a, b, c, d, f = theta[0:nvar]\n",
    "    mplx = theta[nvar:theta.size]\n",
    "    if np.min(mplx) <= 0:\n",
    "        return -np.inf\n",
    "    factor = (au**3.)*((4.0*np.pi**2.)/(g*msun))\n",
    "    empmass = factor*smaper/mplx**3\n",
    "    e_empmass = empmass*(esmaper/smaper)**2\n",
    "    mka = kp - 5.0*(np.log10(1000.0/mplx)-1.)\n",
    "    mkb = ks - 5.0*(np.log10(1000.0/mplx)-1.)\n",
    "    mka -= zp\n",
    "    mkb -= zp\n",
    "    mass1 = (10.0**(a + b*mka + c*mka**2. + d*mka**3.))*(1+f*feh)\n",
    "    mass2 = (10.0**(a + b*mkb + c*mkb**2. + d*mkb**3.))*(1+f*feh)\n",
    "    if np.min(mass1) <= 0 or np.min(mass2) <= 0:\n",
    "        return -np.inf\n",
    "    \n",
    "    ## this is where we check to see if the relation always does brighter=higher mass (if not return -np.inf)\n",
    "    #rng = [np.min(np.concatenate([mka,mkb])),np.max(np.concatenate([mka,mkb]))]\n",
    "    mk = np.linspace(4.2,11.1,100)\n",
    "    l = 10.0**(a + b*(mk-zp) + c*(mk-zp)**2. + d*(mk-zp)**3.)\n",
    "    check = all(l[i] >= l[i+1] for i in xrange(len(l)-1))\n",
    "    if not check:\n",
    "        return -np.inf\n",
    "    ## there's a better way to do this... probably to check to see if the slope goes negative\n",
    "\n",
    "    mka_err = ekp\n",
    "    mkb_err = eks\n",
    "    mass1_err = np.abs((np.log(10.)*(b+2.*c*mka+3.*d*mka**2))*mass1*mka_err)\n",
    "    mass2_err = np.abs((np.log(10.)*(b+2.*c*mkb+3.*d*mkb**2))*mass2*mkb_err)\n",
    "    \n",
    "    model_err = np.sqrt(mass1_err**2+mass2_err**2)\n",
    "    model = mass1+mass2\n",
    "    inv_sigma2 = 1.0/np.sqrt(e_empmass**2+model_err**2)\n",
    "    return -0.5*(np.sum((empmass-model)**2*inv_sigma2 - np.log(inv_sigma2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnprior(theta, plxval, plxprior, nvar):\n",
    "    mplx = theta[nvar:theta.size]\n",
    "    lp = 0\n",
    "    if np.min(mplx) <= 0:\n",
    "        return -np.inf\n",
    "    for i in range(0,len(mplx)):\n",
    "        lp += ((np.float(mplx[i])-np.float(plxval[i]))**2)/(np.float(plxprior[i])**2)\n",
    "    lp*=(-0.5)\n",
    "    if not np.isfinite(lp):\n",
    "        return 0.0\n",
    "    return lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnprob(theta, plxval, plxprior, smaper, esmaper, kp, ks, ekp, eks, feh, nvar):\n",
    "    lp = lnprior(theta, plxval, plxprior, nvar)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    like = lnlike(theta, smaper, esmaper, kp, ks, ekp, eks, feh, nvar)\n",
    "    if not np.isfinite(like):\n",
    "        return -np.inf\n",
    "    val = lp + like\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished burn/test phase runtime (minutes):\n",
      "2.42117058436\n",
      "Mean acceptance fraction: 0.1772\n",
      "Expected time (hours):\n",
      "4.035299725\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "ndim, nwalkers = result.size, 800\n",
    "pos = [result + 1e-2*result*np.random.randn(ndim) for i in range(nwalkers)]\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob, \n",
    "                                args=(plxval, plxprior, smaper, esmaper, kp, ks, ekp, eks, feh, nvar),\n",
    "                               threads=6)\n",
    "## burn-in and/or testing\n",
    "smallstep = 50000\n",
    "bigstep =  600000\n",
    "pos, prob, state = sampler.run_mcmc(pos, smallstep)\n",
    "print 'Finished burn/test phase runtime (minutes):'\n",
    "print (time.time() - start_time)/60\n",
    "print(\"Mean acceptance fraction: {0:.4f}\".format(np.mean(sampler.acceptance_fraction)))\n",
    "print 'Expected time (hours):'\n",
    "print ((time.time() - start_time)/60)*(bigstep/smallstep)/60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.63256721 -0.19612008 -0.00419851  0.00348881  0.00970706]\n",
      " [-0.63256721 -0.19612008 -0.00419851  0.00348881  0.00970706]]\n"
     ]
    }
   ],
   "source": [
    "dat = sampler.chain\n",
    "prob = sampler.lnprobability\n",
    "accept = sampler.acceptance_fraction\n",
    "dat = sampler.flatchain#chain\n",
    "like = sampler.flatlnprobability\n",
    "arr = dat\n",
    "best = (like == max(like))\n",
    "a = arr[best,0:nvar]#np.median(arr[:,0])\n",
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sampler.reset()\n",
    "start_time = time.time()\n",
    "nsteps = bigstep\n",
    "thin = 100\n",
    "kwargs = {'thin': thin }\n",
    "print 'Starting run!'\n",
    "for i, result in enumerate(sampler.sample(pos, iterations=nsteps, **kwargs)):\n",
    "    if (i+1) % 50000 == 0:\n",
    "        print(\"{0:5.1%}\".format(float(i) / nsteps)),\n",
    "        (\"{0:5.2%}\".format((time.time() - start_time)/60))\n",
    "print ' '\n",
    "print 'Done, runtime (hours):'\n",
    "print (time.time() - start_time)/3600\n",
    "print(\"Mean acceptance fraction: {0:.3f}\".format(np.mean(sampler.acceptance_fraction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print dat.shape,nwalkers,nsteps,thin\n",
    "import corner\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "dat = sampler.flatchain#chain\n",
    "like = sampler.flatlnprobability\n",
    "arr = dat\n",
    "\n",
    "fig = corner.corner(arr[:,0:nvar], labels=[r'$a_1$',r'$a_2$',r'$a_3$',r'$a_4$',r'$f$'], show_titles=True, title_kwargs={\"fontsize\": 11},title_fmt='.4f')\n",
    "pp = PdfPages('output_params_feh.pdf')\n",
    "pp.savefig(fig)\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = sampler.chain\n",
    "prob = sampler.lnprobability\n",
    "accept = sampler.acceptance_fraction\n",
    "arr = dat.reshape((dat.shape)[0]*(dat.shape)[1],dat.shape[2])\n",
    "print 'name plx_mcmc plx_err_mcmc plxinput plx_prior diff_sig1 diff_sig2'\n",
    "for i in range(nvar,dat.shape[2]):\n",
    "    print \"{:10s}\".format(name[i-nvar]), \\\n",
    "    i,\\\n",
    "    \"{0:.4f}\".format(np.median(arr[:,i])),\"{0:.4f}\".format(np.std(arr[:,i])),\"{0:.4f}\".format(plxprior[i-nvar]), \\\n",
    "    \"{0:.4f}\".format(plxval[i-nvar]),\"{0:.4f}\".format((plxval[i-nvar]-np.median(arr[:,i]))/plxprior[i-nvar]), \\\n",
    "    \"{0:.4f}\".format((plxval[i-nvar]-np.median(arr[:,i]))/np.sqrt(plxprior[i-nvar]**2+np.std(arr[:,i])**2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = (au**3.)*((4.0*np.pi**2.)/(g*msun))\n",
    "mass = factor*smaper/plxval**3\n",
    "\n",
    "mka = kp - 5.0*(np.log10(1000.0/plxval)-1.)\n",
    "mkb = ks - 5.0*(np.log10(1000.0/plxval)-1.)\n",
    "\n",
    "best = (like == max(like))\n",
    "a = arr[best,0]#np.median(arr[:,0])\n",
    "b = arr[best,1]#np.median(arr[:,1])\n",
    "c = arr[best,2]#np.median(arr[:,2])\n",
    "d = arr[best,3]#np.median(arr[:,3])\n",
    "f = arr[best,5]\n",
    "print a,b,c,d,f\n",
    "\n",
    "mass1 = (10.0**(a + b*(mka-7.5) + c*(mka-7.5)**2 + d*(mka-7.5)**3))*(1+f*feh)\n",
    "mass2 = (10.0**(a + b*(mkb-7.5) + c*(mkb-7.5)**2 + d*(mkb-7.5)**3))*(1+f*feh)\n",
    "sysmass = mass1+mass2\n",
    "a, b, c, d, e = result1\n",
    "mass1 = a + b*(mka-7.5) + c*(mka-7.5)**2 + d*(mka-7.5)**3 + e*(mka-7.5)**4\n",
    "mass2 = a + b*(mkb-7.5) + c*(mkb-7.5)**2 + d*(mkb-7.5)**3 + e*(mkb-7.5)**4\n",
    "sysmass_mann = mass1+mass2\n",
    "a, b, c, d, e = result_ben\n",
    "mass1 = a + b*(mka-7.5) + c*(mka-7.5)**2 + d*(mka-7.5)**3 + e*(mka-7.5)**4\n",
    "mass2 = a + b*(mkb-7.5) + c*(mkb-7.5)**2 + d*(mkb-7.5)**3 + e*(mkb-7.5)**4\n",
    "sysmass_ben = mass1+mass2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print sampler.chain.shape\n",
    "print sampler.lnprobability.shape\n",
    "short = sampler.chain[:,:,0:nvar]\n",
    "print short.shape\n",
    "#print np.median(sampler.chain[:,:,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save out the relevant chains\n",
    "import pyfits\n",
    "pyfits.writeto('Mk-Mass_feh4_emcee.fits', sampler.chain, clobber=True)\n",
    "pyfits.writeto('Mk-Mass_feh4_emcee_short.fits', short, clobber=True)\n",
    "pyfits.writeto('Mk-Mass_feh4_emcee_accept.fits', sampler.acceptance_fraction, clobber=True)\n",
    "pyfits.writeto('Mk-Mass_feh4_emcee_lnprob.fits', sampler.lnprobability, clobber=True)\n",
    "pyfits.writeto('Mk-Mass_feh4_emcee_acor.fits', sampler.acor, clobber=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
